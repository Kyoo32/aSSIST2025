{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 국민건강영양조사 제8기(2019-2021) 데이터 분석\n",
        "> https://kjcn.or.kr/journal/view.php?number=728\n",
        "\n",
        "## 수면건강 변수(X)가 우울증 위험군(Y)에 속할 확률에 어떤 영향을 미치는가\n"
      ],
      "metadata": {
        "id": "hewGiuXLx4Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Dir7MI3ZyIcm"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data preprocessing"
      ],
      "metadata": {
        "id": "srtPhYLh1hNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load KNHANES8 dataset\n",
        "data_file = 'hn21_all.csv'\n",
        "df_raw = pd.read_csv(data_file)\n",
        "\n",
        "# 분석에 필요한 최종 변수 목록\n",
        "selected_columns = [\n",
        "    # 1. Y 변수 (정신건강)\n",
        "    'mh_GAD_S',       # 범불안장애 선별도구 7항목 점수 합\n",
        "\n",
        "    # 2. X 변수 (수면건강)\n",
        "    'BP16_11',       # (만12세이상) 주중 잠자리에 든 시각_시간\n",
        "    'BP16_13',       # (만12세이상) 주중 일어난 시각_시\n",
        "    'BP16_21',       # (만12세이상) 주말 잠자리에 든 시각_시\n",
        "    'BP16_23',       # (만12세이상) 주말 일어난 시각_시\n",
        "    'BP17_2',        # 코골이\n",
        "    'BP17_3',        # 주간 피곤\n",
        "    'BP17_4',        # 수면 중 무호흡\n",
        "\n",
        "    # 3. X 변수 (통제 변수)\n",
        "    'age',           # 나이\n",
        "    'sex',           # 성별\n",
        "    'incm5',         # 소득 (5분위)\n",
        "    'edu',           # 교육 수준\n",
        "    'marri_1',       # 결혼 상태\n",
        "    'mh_stress',     # 스트레스 인지율\n",
        "    'sm_presnt',     # 현재 흡연 여부\n",
        "    'dr_month',      # 월간 음주 빈도\n",
        "    'pa_aerobic',    # 신체 활동\n",
        "    'HE_BMI',        # BMI\n",
        "    'DI1_dg',        # 고혈압 진단\n",
        "    'DE1_dg',        # 당뇨병 진단\n",
        "\n",
        "    # 4. ID 및 가중치 (데이터 관리에 필요)\n",
        "    'ID',            # 개인 ID\n",
        "    'year'           # 조사 연도\n",
        "]\n",
        "\n",
        "# 원본 DataFrame(df_raw)에서 필요한 컬럼만 선택\n",
        "# KeyError 방지를 위해 실제 파일에 있는 컬럼만 선택\n",
        "existing_cols = [col for col in selected_columns if col in df_raw.columns]\n",
        "df = df_raw[existing_cols].copy()\n",
        "\n",
        "print(f\"선택된 컬럼 수: {len(existing_cols)}\")\n",
        "\n",
        "\n",
        "# --- 1) 연령 제한 ---\n",
        "# 만 19세 이상 성인 데이터만 필터링\n",
        "df = df[df['age'] >= 19].copy()\n",
        "print(f\"19세 이상 데이터 수: {len(df)}\")\n",
        "\n",
        "\n",
        "# --- 2) Y 변수 처리 (is_anxious 생성) ---\n",
        "print(\"\\n=== Y 변수 처리 중 ===\")\n",
        "\n",
        "# GAD-7 총점 결측치(88: 비해당(19세미만), 99: 모름/무응답)를 np.nan으로 변환\n",
        "df['mh_GAD_S'] = df['mh_GAD_S'].replace([88, 99], np.nan)\n",
        "\n",
        "# Y 변수가 결측치인 행은 분석에서 제외 (매우 중요)\n",
        "df.dropna(subset=['mh_GAD_S'], inplace=True)\n",
        "\n",
        "# Y 변수 생성: 7점 이상을 '불안 위험군(1)', 미만을 '정상군(0)'으로 분류\n",
        "df['is_anxious'] = (df['mh_GAD_S'] >= 7).astype(int)\n",
        "print(f\"Y 변수('is_anxious') 생성 완료. (결측 제거 후 데이터 수: {len(df)})\")\n",
        "\n",
        "\n",
        "# --- 3) X 변수 전처리 ---\n",
        "print(\"\\n=== X 변수 전처리 중 ===\")\n",
        "\n",
        "# 3-1. 파생 변수 생성: 수면 시간 (Feature Engineering)\n",
        "sleep_time_cols = ['BP16_11', 'BP16_13', 'BP16_21', 'BP16_23']\n",
        "# 수면 시각 결측치(88, 99) np.nan으로 변환\n",
        "df[sleep_time_cols] = df[sleep_time_cols].replace([88, 99], np.nan)\n",
        "\n",
        "# (주중) 수면 시간 계산 (자정 문제 해결)\n",
        "df['sleep_duration_wk'] = np.where(\n",
        "    df['BP16_13'] >= df['BP16_11'],\n",
        "    df['BP16_13'] - df['BP16_11'],    # 자정 안 넘는 경우 (예: 1시~7시)\n",
        "    (24 - df['BP16_11']) + df['BP16_13'] # 자정 넘는 경우 (예: 23시~7시)\n",
        ")\n",
        "\n",
        "# (주말) 수면 시간 계산 (자정 문제 해결)\n",
        "df['sleep_duration_we'] = np.where(\n",
        "    df['BP16_23'] >= df['BP16_21'],\n",
        "    df['BP16_23'] - df['BP16_21'],\n",
        "    (24 - df['BP16_21']) + df['BP16_23']\n",
        ")\n",
        "\n",
        "# (보너스) 주중/주말 수면 시간 차이 (사회적 시차)\n",
        "df['sleep_duration_diff'] = df['sleep_duration_we'] - df['sleep_duration_wk']\n",
        "\n",
        "\n",
        "# 3-2. X 변수 결측치(Missing Value) 처리\n",
        "# 1-digit 결측 코드(8, 9)를 사용하는 변수들\n",
        "cols_clean_1 = ['BP17_2', 'BP17_3', 'BP17_4', 'incm5', 'edu', 'marri_1',\n",
        "                'mh_stress', 'sm_presnt', 'pa_aerobic', 'DI1_dg', 'DE1_dg']\n",
        "df[cols_clean_1] = df[cols_clean_1].replace([8, 9], np.nan)\n",
        "\n",
        "# 2-digit 결측 코드(88, 99)를 사용하는 변수들\n",
        "cols_clean_2 = ['dr_month']\n",
        "df[cols_clean_2] = df[cols_clean_2].replace([88, 99], np.nan)\n",
        "\n",
        "# 3-digit 이상 결측 코드(999 등)를 사용하는 변수들\n",
        "df['HE_BMI'] = df['HE_BMI'].replace([999, 999.9], np.nan)\n",
        "\n",
        "\n",
        "# 3-3. (선택적) 이진 변수 리코딩 (1=Yes, 2=No -> 1=Yes, 0=No)\n",
        "# 로지스틱 회귀 등에서 해석을 용이하게 합니다 (0=No가 기준점이 됨)\n",
        "cols_recode_1_2 = ['BP17_2', 'BP17_3', 'BP17_4', 'pa_aerobic', 'DI1_dg', 'DE1_dg']\n",
        "df[cols_recode_1_2] = df[cols_recode_1_2].replace(2, 0) # 2(아니오)를 0으로 변경\n",
        "\n",
        "print(\"X 변수 파생 및 결측치 처리 완료.\")\n",
        "\n",
        "\n",
        "# --- 4) 최종 모델링 데이터프레임 생성 ---\n",
        "# 분석에 사용할 최종 X, Y 변수 목록\n",
        "final_model_columns = [\n",
        "    'is_anxious',             # Y\n",
        "    'sleep_duration_wk',      # X (수면시간)\n",
        "    'sleep_duration_we',      # X (수면시간)\n",
        "    'sleep_duration_diff',    # X (수면시간)\n",
        "    'BP17_2',                 # X (수면의 질)\n",
        "    'BP17_3',                 # X (수면의 질)\n",
        "    'BP17_4',                 # X (수면의 질)\n",
        "    'age',                    # X (통제)\n",
        "    'sex',                    # X (통제)\n",
        "    'incm5',                  # X (통제)\n",
        "    'edu',                    # X (통제)\n",
        "    'marri_1',                # X (통제)\n",
        "    'mh_stress',              # X (통제)\n",
        "    'sm_presnt',              # X (통제)\n",
        "    'dr_month',               # X (통제)\n",
        "    'pa_aerobic',             # X (통제)\n",
        "    'HE_BMI',                 # X (통제)\n",
        "    'DI1_dg',                 # X (통제)\n",
        "    'DE1_dg'                  # X (통제)\n",
        "]\n",
        "\n",
        "# 위 컬럼 중 하나라도 결측치가 있는 행은 모두 제거\n",
        "df_model = df[final_model_columns].dropna().copy()\n",
        "\n",
        "print(f\"\\n=== 최종 모델링 데이터 생성 완료 ===\")\n",
        "print(f\"원본 데이터: {len(df_raw)} 행\")\n",
        "print(f\"최종 분석 데이터: {len(df_model)} 행 (19세 이상, 결측치 제거)\")\n",
        "\n",
        "# 최종 데이터 확인\n",
        "print(\"\\n--- 최종 데이터 정보 (df_model.info()) ---\")\n",
        "df_model.info()\n",
        "\n",
        "print(\"\\n--- 최종 데이터 샘플 (df_model.head()) ---\")\n",
        "print(df_model.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PydYkMYyKnD",
        "outputId": "c5cf223b-2eef-4c89-9345-156327c7025b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 컬럼 수: 22\n",
            "19세 이상 데이터 수: 5952\n",
            "\n",
            "=== Y 변수 처리 중 ===\n",
            "Y 변수('is_anxious') 생성 완료. (결측 제거 후 데이터 수: 5615)\n",
            "\n",
            "=== X 변수 전처리 중 ===\n",
            "X 변수 파생 및 결측치 처리 완료.\n",
            "\n",
            "=== 최종 모델링 데이터 생성 완료 ===\n",
            "원본 데이터: 7090 행\n",
            "최종 분석 데이터: 3916 행 (19세 이상, 결측치 제거)\n",
            "\n",
            "--- 최종 데이터 정보 (df_model.info()) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3916 entries, 0 to 7087\n",
            "Data columns (total 19 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   is_anxious           3916 non-null   int64  \n",
            " 1   sleep_duration_wk    3916 non-null   float64\n",
            " 2   sleep_duration_we    3916 non-null   float64\n",
            " 3   sleep_duration_diff  3916 non-null   float64\n",
            " 4   BP17_2               3916 non-null   float64\n",
            " 5   BP17_3               3916 non-null   float64\n",
            " 6   BP17_4               3916 non-null   float64\n",
            " 7   age                  3916 non-null   float64\n",
            " 8   sex                  3916 non-null   float64\n",
            " 9   incm5                3916 non-null   float64\n",
            " 10  edu                  3916 non-null   float64\n",
            " 11  marri_1              3916 non-null   float64\n",
            " 12  mh_stress            3916 non-null   float64\n",
            " 13  sm_presnt            3916 non-null   float64\n",
            " 14  dr_month             3916 non-null   float64\n",
            " 15  pa_aerobic           3916 non-null   float64\n",
            " 16  HE_BMI               3916 non-null   float64\n",
            " 17  DI1_dg               3916 non-null   float64\n",
            " 18  DE1_dg               3916 non-null   float64\n",
            "dtypes: float64(18), int64(1)\n",
            "memory usage: 611.9 KB\n",
            "\n",
            "--- 최종 데이터 샘플 (df_model.head()) ---\n",
            "   is_anxious  sleep_duration_wk  sleep_duration_we  sleep_duration_diff  \\\n",
            "0           0                6.0                6.0                  0.0   \n",
            "1           0                6.0                7.0                  1.0   \n",
            "4           0                8.0                8.0                  0.0   \n",
            "5           1                5.0                5.0                  0.0   \n",
            "6           0                7.0                7.0                  0.0   \n",
            "\n",
            "   BP17_2  BP17_3  BP17_4   age  sex  incm5  edu  marri_1  mh_stress  \\\n",
            "0     0.0     0.0     0.0  61.0  1.0    4.0  3.0      2.0        0.0   \n",
            "1     0.0     0.0     0.0  57.0  1.0    3.0  3.0      1.0        0.0   \n",
            "4     0.0     0.0     0.0  70.0  1.0    2.0  2.0      1.0        0.0   \n",
            "5     0.0     0.0     0.0  72.0  2.0    3.0  2.0      1.0        1.0   \n",
            "6     0.0     1.0     1.0  77.0  2.0    5.0  1.0      1.0        1.0   \n",
            "\n",
            "   sm_presnt  dr_month  pa_aerobic     HE_BMI  DI1_dg  DE1_dg  \n",
            "0        0.0       1.0         1.0  26.789017     1.0     0.0  \n",
            "1        0.0       1.0         1.0  25.506641     1.0     0.0  \n",
            "4        1.0       0.0         0.0  18.993831     0.0     0.0  \n",
            "5        0.0       0.0         0.0  28.166306     0.0     0.0  \n",
            "6        0.0       0.0         0.0  21.040991     0.0     0.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2782318300.py:3: DtypeWarning: Columns (140,380,513,660,671) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_raw = pd.read_csv(data_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Logistic Regression & ODDS Ratio 분석하기\n",
        "### is_anxious ~ BP17_2 + BP17_3 + BP17_4 +  ...\n"
      ],
      "metadata": {
        "id": "lYhdOwPm8UuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "I1qHdmEJ9Bed"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_model은 이전 단계에서 생성한 최종 데이터프레임입니다.\n",
        "\n",
        "# --- 3.1: X, Y 분리 및 원-핫 인코딩 ---\n",
        "\n",
        "# Y 변수 (종속 변수)\n",
        "y = df_model['is_anxious']\n",
        "\n",
        "# X 변수 (독립 변수)\n",
        "X = df_model.drop('is_anxious', axis=1)\n",
        "\n",
        "# X 변수 중 범주형/연속형 변수 이름 정의\n",
        "# (리코딩해서 0/1이 된 변수들은 스케일링이나 인코딩이 불필요)\n",
        "binary_features = ['BP17_2', 'BP17_3', 'BP17_4', 'pa_aerobic', 'DI1_dg', 'DE1_dg']\n",
        "continuous_features = ['age', 'HE_BMI', 'sleep_duration_wk', 'sleep_duration_we', 'sleep_duration_diff']\n",
        "categorical_features = ['sex', 'incm5', 'edu', 'marri_1', 'mh_stress', 'sm_presnt', 'dr_month']\n",
        "\n",
        "# 범주형 변수(categorical_features)를 원-핫 인코딩 (One-Hot Encoding)\n",
        "# drop_first=True : 더미 변수 함정(다중공선성)을 방지합니다. (e.g., sex_1만 남기고 sex_2는 제거)\n",
        "X_processed = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "print(\"원-핫 인코딩 후 X 변수 컬럼:\", X_processed.columns.tolist())\n",
        "\n",
        "\n",
        "# --- 3.2: 훈련/테스트 데이터 분리 및 스케일링 ---\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 분리 (80% / 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 연속형 변수(continuous_features) 스케일링\n",
        "# 스케일러는 훈련 데이터(X_train)로만 '학습(fit)'해야 합니다. (데이터 누수 방지)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 훈련 데이터에 맞춰 스케일링 적용\n",
        "X_train[continuous_features] = scaler.fit_transform(X_train[continuous_features])\n",
        "# 테스트 데이터에도 동일한 스케일러 적용\n",
        "X_test[continuous_features] = scaler.transform(X_test[continuous_features])\n",
        "\n",
        "print(\"\\n데이터 분리 및 스케일링 완료.\")\n",
        "\n",
        "\n",
        "# --- 3.3: 로지스틱 회귀 모델 학습 ---\n",
        "\n",
        "# 로지스틱 회귀 모델 생성 및 학습\n",
        "# C=1.0 : 정규화(Regularization) 강도 조절 (낮을수록 강한 정규화)\n",
        "# 'l2' (Ridge) : 과적합(Overfitting)을 방지하는 L2 정규화 사용\n",
        "log_reg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', random_state=42, max_iter=1000, class_weight='balanced')\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# (참고) 모델 성능 평가\n",
        "y_pred = log_reg.predict(X_test)\n",
        "print(\"\\n=== 모델 정확도 ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# --- 3.4: 결과 해석 (오즈비 계산) ---\n",
        "print(\"\\n=== 로지스틱 회귀 계수 및 오즈비(Odds Ratio) ===\")\n",
        "\n",
        "# 원-핫 인코딩된 X의 컬럼명 가져오기\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# 모델의 계수(coefficients) 가져오기\n",
        "coefficients = log_reg.coef_[0]\n",
        "\n",
        "# 계수를 지수 변환(exp)하여 오즈비(Odds Ratio) 계산\n",
        "odds_ratios = np.exp(coefficients)\n",
        "\n",
        "# 해석하기 쉬운 DataFrame으로 만들기\n",
        "coeff_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient (Log-Odds)': coefficients,\n",
        "    'Odds Ratio': odds_ratios\n",
        "})\n",
        "\n",
        "# 오즈비 기준으로 내림차순 정렬 (영향력이 큰 변수 확인)\n",
        "coeff_df = coeff_df.sort_values(by='Odds Ratio', ascending=False)\n",
        "\n",
        "print(coeff_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iWUDJaB_9DRE",
        "outputId": "9b13cb2e-2e33-4fc8-ebe2-2e2ca2827ee0"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원-핫 인코딩 후 X 변수 컬럼: ['sleep_duration_wk', 'sleep_duration_we', 'sleep_duration_diff', 'BP17_2', 'BP17_3', 'BP17_4', 'age', 'pa_aerobic', 'HE_BMI', 'DI1_dg', 'DE1_dg', 'sex_2.0', 'incm5_2.0', 'incm5_3.0', 'incm5_4.0', 'incm5_5.0', 'edu_2.0', 'edu_3.0', 'edu_4.0', 'marri_1_2.0', 'mh_stress_1.0', 'sm_presnt_1.0', 'dr_month_1.0']\n",
            "\n",
            "데이터 분리 및 스케일링 완료.\n",
            "\n",
            "=== 모델 정확도 ===\n",
            "Accuracy: 0.7921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.80      0.88       735\n",
            "           1       0.19      0.73      0.31        49\n",
            "\n",
            "    accuracy                           0.79       784\n",
            "   macro avg       0.59      0.77      0.59       784\n",
            "weighted avg       0.93      0.79      0.84       784\n",
            "\n",
            "\n",
            "=== 로지스틱 회귀 계수 및 오즈비(Odds Ratio) ===\n",
            "                Feature  Coefficient (Log-Odds)  Odds Ratio\n",
            "20        mh_stress_1.0                2.537812   12.651957\n",
            "4                BP17_3                0.819116    2.268494\n",
            "11              sex_2.0                0.568614    1.765819\n",
            "19          marri_1_2.0                0.371170    1.449430\n",
            "5                BP17_4                0.228968    1.257302\n",
            "21        sm_presnt_1.0                0.185937    1.204347\n",
            "7            pa_aerobic                0.085853    1.089646\n",
            "10               DE1_dg                0.070555    1.073103\n",
            "0     sleep_duration_wk                0.003867    1.003874\n",
            "8                HE_BMI               -0.056328    0.945229\n",
            "1     sleep_duration_we               -0.081805    0.921452\n",
            "22         dr_month_1.0               -0.094546    0.909786\n",
            "2   sleep_duration_diff               -0.120148    0.886790\n",
            "6                   age               -0.135245    0.873502\n",
            "9                DI1_dg               -0.191693    0.825561\n",
            "3                BP17_2               -0.324094    0.723182\n",
            "16              edu_2.0               -0.343103    0.709565\n",
            "15            incm5_5.0               -0.378052    0.685195\n",
            "14            incm5_4.0               -0.458858    0.632005\n",
            "17              edu_3.0               -0.484394    0.616071\n",
            "13            incm5_3.0               -0.505128    0.603428\n",
            "12            incm5_2.0               -0.648659    0.522747\n",
            "18              edu_4.0               -0.893057    0.409402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. XGBoost로 중요한 특성 찾기\n",
        "개별 모델의 한계를 극복하고, \"정신건강에 가장 큰 영향을 미치는 요인\"의 종합 순위 매기기"
      ],
      "metadata": {
        "id": "s_WAGlmGCD4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier # XGBoost 임포트\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter # 비율 계산을 위해 임포트"
      ],
      "metadata": {
        "id": "wRLqqa1PCW54"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test는 이전 단계에서\n",
        "# 스케일링과 원-핫 인코딩이 완료된 데이터라고 가정합니다.\n",
        "\n",
        "# --- 4.1: scale_pos_weight 계산 ---\n",
        "# 훈련 데이터(y_train)의 클래스 비율을 계산합니다.\n",
        "counter = Counter(y_train)\n",
        "count_0 = counter[0] # 다수 클래스 (정상군)\n",
        "count_1 = counter[1] # 소수 클래스 (불안 위험군)\n",
        "\n",
        "scale_pos_weight = count_0 / count_1\n",
        "\n",
        "print(f\"=== XGBoost 파라미터 계산 ===\")\n",
        "print(f\"훈련 데이터: 정상군(0)={count_0}명, 위험군(1)={count_1}명\")\n",
        "print(f\"scale_pos_weight 값: {scale_pos_weight:.2f}\")\n",
        "\n",
        "\n",
        "# --- 4.2: XGBoost 모델 학습 ---\n",
        "# use_label_encoder=False : 최신 XGBoost의 경고 메시지를 없애기 위함\n",
        "# eval_metric='logloss' : 분류 문제의 표준 평가 지표\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=scale_pos_weight, # <--- 핵심 파라미터!\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\n=== XGBoost 모델 학습 시작... ===\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"학습 완료.\")\n",
        "\n",
        "\n",
        "# --- 4.3: 성능 평가 ---\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"\\n=== XGBoost 모델 정확도 ===\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "\n",
        "# --- 4.4: 특성 중요도(Feature Importances) 추출 ---\n",
        "\n",
        "# 특성 중요도 추출\n",
        "importances = xgb_model.feature_importances_\n",
        "\n",
        "# X_train의 컬럼명 가져오기\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# 컬럼명과 중요도 점수를 매칭하여 DataFrame 생성\n",
        "importance_df_xgb = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 중요도(Importance)가 높은 순서대로 정렬\n",
        "importance_df_xgb = importance_df_xgb.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== 특성 중요도 (Top 10) ===\")\n",
        "print(importance_df_xgb.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9wstQECCNyB",
        "outputId": "ee66bc19-aa5c-4a35-84ee-d929b1b8d159"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:18:47] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== XGBoost 파라미터 계산 ===\n",
            "훈련 데이터: 정상군(0)=2863명, 위험군(1)=269명\n",
            "scale_pos_weight 값: 10.64\n",
            "\n",
            "=== XGBoost 모델 학습 시작... ===\n",
            "학습 완료.\n",
            "\n",
            "=== XGBoost 모델 정확도 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94       735\n",
            "           1       0.14      0.16      0.15        49\n",
            "\n",
            "    accuracy                           0.89       784\n",
            "   macro avg       0.54      0.55      0.55       784\n",
            "weighted avg       0.89      0.89      0.89       784\n",
            "\n",
            "\n",
            "=== 특성 중요도 (Top 10) ===\n",
            "                Feature  Importance\n",
            "20        mh_stress_1.0    0.360932\n",
            "4                BP17_3    0.059188\n",
            "18              edu_4.0    0.047801\n",
            "2   sleep_duration_diff    0.037051\n",
            "16              edu_2.0    0.034394\n",
            "12            incm5_2.0    0.033324\n",
            "17              edu_3.0    0.033066\n",
            "0     sleep_duration_wk    0.030450\n",
            "15            incm5_5.0    0.030344\n",
            "11              sex_2.0    0.030066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#5.1. SMOTE 객체 생성\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# 5.2. 훈련 데이터(X_train, y_train)에만 SMOTE를 적용\n",
        "print(\"SMOTE 오버샘플링 시작...\")\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "print(\"오버샘플링 완료.\")\n",
        "print(f\"원본 훈련 데이터: {Counter(y_train)}\")\n",
        "print(f\"SMOTE 적용 후 훈련 데이터: {Counter(y_train_resampled)}\")\n",
        "\n",
        "# 5.3. '균형이 맞춰진' 새 데이터로 XGBoost 모델 재학습\n",
        "# (SMOTE를 사용했으므로 scale_pos_weight 파라미터는 제거합니다)\n",
        "xgb_model_smote = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nSMOTE 적용 XGBoost 모델 학습 시작...\")\n",
        "xgb_model_smote.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"학습 완료.\")\n",
        "\n",
        "# 5.4. 최종 성능 및 특성 중요도 확인\n",
        "y_pred_smote = xgb_model_smote.predict(X_test)\n",
        "\n",
        "print(\"\\n=== SMOTE + XGBoost 모델 정확도 ===\")\n",
        "print(classification_report(y_test, y_pred_smote))\n",
        "\n",
        "# --- 5.4: 특성 중요도(Feature Importances) 추출 ---\n",
        "\n",
        "importances = xgb_model_smote.feature_importances_\n",
        "feature_names = X_train_resampled.columns\n",
        "\n",
        "importance_df_xgb_smote = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 중요도(Importance)가 높은 순서대로 정렬\n",
        "importance_df_xgb_smote = importance_df_xgb_smote.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== 특성 중요도 (Top 10) ===\")\n",
        "print(importance_df_xgb_smote.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yruzpmBJGgoe",
        "outputId": "c377e89b-06bd-4e96-f48a-8fc8d66869c1"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 오버샘플링 시작...\n",
            "오버샘플링 완료.\n",
            "원본 훈련 데이터: Counter({0: 2863, 1: 269})\n",
            "SMOTE 적용 후 훈련 데이터: Counter({0: 2863, 1: 2863})\n",
            "\n",
            "SMOTE 적용 XGBoost 모델 학습 시작...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:18:47] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 완료.\n",
            "\n",
            "=== SMOTE + XGBoost 모델 정확도 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       735\n",
            "           1       0.19      0.18      0.19        49\n",
            "\n",
            "    accuracy                           0.90       784\n",
            "   macro avg       0.57      0.57      0.57       784\n",
            "weighted avg       0.90      0.90      0.90       784\n",
            "\n",
            "\n",
            "=== 특성 중요도 (Top 10) ===\n",
            "                Feature  Importance\n",
            "20        mh_stress_1.0    0.555074\n",
            "11              sex_2.0    0.056627\n",
            "4                BP17_3    0.048875\n",
            "7            pa_aerobic    0.029747\n",
            "19          marri_1_2.0    0.028802\n",
            "3                BP17_2    0.027466\n",
            "10               DE1_dg    0.026643\n",
            "9                DI1_dg    0.021804\n",
            "2   sleep_duration_diff    0.021508\n",
            "21        sm_presnt_1.0    0.018657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o6VIVJfuMRvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **수면과 정신건강의 관계 분석 최종 보고서**\n",
        "\n",
        "**1. 분석 요약 (Executive Summary)**\n",
        "본 분석은 2021년 국민건강영양조사(19세 이상) 데이터를 활용하여, 수면 건강 및 기타 생활 습관 요인이 불안장애 위험군(`is_anxious=1`)에 미치는 영향을 규명하고자 하였다. 데이터의 심각한 불균형 문제를 해결하기 위해 로지스틱 회귀(LR), XGBoost 등 다양한 모델과 `class_weight`, `scale_pos_weight`, `SMOTE` 기법을 적용하여 비교 분석하였다.\n",
        "\n",
        "분석 결과, **`class_weight='balanced'`를 적용한 로지스틱 회귀 모델**이 불안 위험군을 **73%의 재현율(Recall)로 탐지**하며 가장 우수한 성능을 보였다. 이 모델을 통해 **스트레스가 불안 위험을 12.7배 높이는 압도적인 1위 요인**임을 확인했으며, **'주간 피로감'으로 대표되는 수면의 질 저하(2.3배)가 그 뒤를 잇는 핵심 위험 요인**임을 입증했다. 또한, 충분한 수면 시간은 불안을 완화하는 보호 요인으로 작용했다.\n",
        "\n",
        "**2. 모델 성능 비교: 최적의 모델을 찾아서**\n",
        "\n",
        "\n",
        "분석 초기, 표준적인 앙상블 모델(Random Forest, XGBoost)들은 극심한 데이터 불균형(정상군:위험군 ≈ 25:1)으로 인해 불안 위험군을 거의 예측하지 못했다(Recall 0%~18%). 이는 `scale_pos_weight`나 `SMOTE` 같은 고급 기법으로도 완전히 해결되지 않았다.\n",
        "\n",
        "반면, **`class_weight='balanced'`를 적용한 로지스틱 회귀(LR) 모델**은 비록 정밀도(Precision)는 낮았지만, **실제 위험군 10명 중 7명 이상을 찾아내는(Recall 73%)** 실용적인 탐지 성능을 보여주어, 본 분석의 최종 해석 모델로 채택되었다.\n",
        "\n",
        "| 모델 | **불안 위험군(1) 재현율(Recall)** | **평가** |\n",
        "| :--- | :---: | :--- |\n",
        "| **로지스틱 회귀 + `class_weight`** | **73%** | **성공 (최적 모델)** |\n",
        "| XGBoost + `scale_pos_weight` | 16% | 실패 |\n",
        "| XGBoost + SMOTE | 18% | 실패 |\n",
        "\n",
        "**3. 주요 발견 및 해석 (From Best Model: Logistic Regression)**\n",
        "\n",
        "#### **A. 가장 강력한 위험 요인: 스트레스**\n",
        "모든 모델에서 일관되게 가장 중요한 변수로 지목된 **스트레스(`mh_stress`)**는, 최종 모델에서 불안 위험을 **12.7배**나 높이는 압도적인 요인으로 나타났다. 이는 정신건강을 논할 때 스트레스 관리가 최우선 과제임을 시사한다.\n",
        "\n",
        "#### **B. 수면의 질과 불안의 관계: \"어떻게 자는가?\"**\n",
        "수면의 질 저하는 불안 위험을 높이는 명백한 위험 신호였다.\n",
        "* **주간 피로감 (`BP17_3`):** 낮에 피로감을 느끼는 것은 불안 위험을 **2.27배** 높였다. 이는 밤새 뒤척이거나 깊게 잠들지 못하는 등 수면의 질이 정신건강과 직결됨을 보여준다.\n",
        "* **수면 중 무호흡 (`BP17_4`):** 수면 중 무호흡 증상은 불안 위험을 **1.26배** 높였다.\n",
        "\n",
        "#### **C. 수면의 양과 불안의 관계: \"얼마나 자는가?\"**\n",
        "충분한 수면은 불안을 완화하는 보호 요인으로 작용했다.\n",
        "* **주말 수면 시간 (`sleep_duration_we`):** 주말 수면이 1시간 늘어날수록 불안 위험이 **약 8% 감소**했다. 주중에 부족했던 잠을 주말에 보충하는 것이 정신건강에 긍정적인 영향을 미칠 수 있음을 시사한다.\n",
        "\n",
        "**4. 한계점 및 제언**\n",
        "* **한계점:** 본 분석의 최적 모델은 위험군을 놓치지 않고 찾아내는 데(높은 재현율) 초점을 맞춘 결과, 정상인을 위험군으로 잘못 판단하는(낮은 정밀도, 19%) 한계가 있다.\n",
        "* **제언:** 본 분석 결과는 **\"스트레스 관리\"**와 **\"수면의 질 개선(주간 피로감 해소)\"**이 국민 정신건강 증진을 위한 핵심 개입 요소임을 강력히 시사한다. 향후 정밀도를 개선하기 위한 모델 튜닝 및 추가 변수 탐색 연구가 필요하다.\n",
        "\n",
        "---\n",
        "### **최종 결론**\n",
        "이번 데이터 분석 여정을 통해, 우리는 **스트레스**가 정신건강을 위협하는 가장 큰 요인이며, **수면의 질과 양** 역시 불안과 매우 밀접한 관계를 맺고 있음을 통계적으로 입증했다. 특히, 단순히 '얼마나 오래 자는가'를 넘어 '얼마나 잘 자는가'가 정신건강에 매우 중요한 요소임을 확인한 것은 본 분석의 핵심적인 성과이다."
      ],
      "metadata": {
        "id": "q9GcfZJgC92K"
      }
    }
  ]
}